{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a97254a-bb2b-46bf-974c-c95cf8ca1108",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81efa34-38f8-4e63-80eb-7b7f17459f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63852a2-0205-4b7f-87b9-4afe82eae3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3298f9d6-bac6-423b-b676-57c778e0e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG TUTORIAL\"\n",
    "\n",
    "# tracing 을 위해서는 아래 코드의 주석을 해제하고 실행합니다.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844023b-415b-48b4-ac43-8f47e2337ab4",
   "metadata": {},
   "source": [
    "## ollama test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3328c6-e520-4944-8d76-8f2c151907a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s break down LangChain in a way that makes sense! \\n\\n**What is LangChain?**  LangChain is like a powerful toolbox specifically designed for building more sophisticated and complex applications powered by Large Language Models (LLMs).  Think of it like this:\\n\\n* **LLMs (like ChatGPT) are the brains:** These models are great at generating text, translating languages, writing different kinds of creative content, and answering your questions in an informative way. \\n* **LangChain is the scaffolding:** It provides a framework that helps you connect LLMs to other data sources (like websites, documents, databases), interact with them in meaningful ways, and build much more dynamic applications.\\n\\n**Here\\'s a simple analogy:** Imagine you have a really smart assistant who can write poems, answer your questions, and even summarize articles. But, you want to go beyond just having the \"assistant\" tell you things. You want it to connect with other data sources (like news websites or your personal files) to provide more complete answers and information. LangChain is like the bridge that allows this assistant to access and utilize those external resources. \\n\\n\\n**Key features of LangChain:**\\n\\n* **Chain creation:**  Connect LLM calls in a chain, allowing for logic flow between them (like \"get data from this document,\" then \"use the data to answer this question\").\\n* **Data integration:**  LangChain allows you to connect your LLMs to various data sources like databases, APIs, and documents. \\n* **Agent development:** Create AI agents that can interact with the world and follow instructions to solve problems or complete tasks (think autonomous chatbots).\\n* **Memory management:** LLMs often need context to provide better responses; LangChain helps maintain that context over time.\\n\\n\\n**In short:** LangChain simplifies and streamlines the process of creating applications that leverage the power of LLMs by providing a modular and flexible framework for building complex LLM-powered systems!  \\n\\n\\n\\nDo you have any specific questions about LangChain or how it might apply to your project? \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model_name = \"gemma2:2b\"\n",
    "model = OllamaLLM(model=model_name)\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9663b-e332-43e4-b41d-4d7d2af8c908",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Naver News QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbb77e5-f250-4645-a8f8-3ab78d0cf378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"\\n출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\\n\\n\\n[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세 아이는 100만원으로 올렸습니다. 여기에 첫만남이용권, 아동수당까지 더하면 아이 돌까지 1년 동안 1520만원을 받습니다. 지자체도 경쟁하듯 지원에 나섰습니다. 인천시는 새로 태어난 아기, 18살될 때까지 1억원을 주겠다. 광주시도 17살될 때까지 7400만원 주겠다고 했습니다. 선거 때면 나타나서 아이 낳으면 현금 주겠다고 밝힌 사람이 있었죠. 과거에는 표만 노린 '황당 공약'이라는 비판이 따라다녔습니다. 그런데 지금은 출산율이 이보다 더 나쁠 수 없다보니, 이런 현금성 지원을 진지하게 정책화 하는 상황까지 온 겁니다. 게다가 기업들도 뛰어들고 있습니다. 이번에는 출산한 직원에게 단번에 1억원을 주겠다는 회사까지 나타났습니다.이상화 기자가 취재했습니다.[기자]한 그룹사가 오늘 파격적인 저출생 정책을 내놨습니다.2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 이 정책을 이어가기로 했습니다.해당 기간에 연년생과 쌍둥이 자녀가 있으면 총 2억원을 받게 됩니다.[오현석/부영그룹 직원 : 아이 키우는 데 금전적으로 많이 힘든 세상이잖아요. 교육이나 생활하는 데 큰 도움이 될 거라 생각합니다.]만약 셋째까지 낳는 경우엔 국민주택을 제공하겠다는 뜻도 밝혔습니다.[이중근/부영그룹 회장 : 3년 이내에 세 아이를 갖는 분이 나올 것이고 따라서 주택을 제공할 수 있는 계기가 될 것으로 생각하고.][조용현/부영그룹 직원 : 와이프가 셋째도 갖고 싶어 했는데 경제적 부담 때문에 부정적이었거든요. (이제) 긍정적으로 생각할 수 있을 것 같습니다.]오늘 행사에서는, 회사가 제공하는 출산장려금은 받는 직원들의 세금 부담을 고려해 정부가 면세해달라는 제안도 나왔습니다.이같은 출산장려책은 점점 확산하는 분위기입니다.법정기간보다 육아휴직을 길게 주거나, 남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]\\n\\t\\t\\n\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\",\n",
    "                             \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636a2fad-52dd-4a14-8471-eefb8360c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f78773-0551-4e5e-ad02-666ddbb28eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OllamaEmbeddings(model=model_name)\n",
    ")\n",
    "\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00cab424-222f-4dbf-8545-338d3949a904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\rag-f3KTP8yE-py3.12\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d8434c-d11e-4e50-89b5-1560ae36e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad79bae-0e84-483a-b0ba-8c80cef83baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'부영그룹은 출산한 직원에게 2021년 이후 태어난 자녀에 1억 원씩 총 70억 원을 지원하는 출산장려 정책을 내렸습니다. 또한 셋째까지 아이를 낳으면 국민주택 제공도 확정했습니다. 부영그룹은 기업들이 출산 장려 정책을 진행하고 있다는 점에서 이에 대한 사회적 공감을 높일 것으로 예상됩니다.  \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\n",
    "    \"부영그룹의 출산 장려 정책에 대해 설명해주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7982c624-f530-4f13-a66d-d09c591669a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the government's low birth rate support measures in bullet points:\n",
      "\n",
      "* **Monthly parent allowance:**  Paid to parents of infants born each month.\n",
      "* **0-year-old child allowances:** Increased from 100,000 won to 200,000 won (exact amount varies by region).\n",
      "* **Child care support (until age 3):**  Offered through programs and subsidies for childcare expenses.\n",
      "\n",
      "\n",
      "Please note that the provided text mentions specific government support measures such as monthly allowances and child care support, but there is no information regarding tax benefits.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_chain.invoke(\"정부의 저출생 대책을 bullet points 형식으로 작성해 주세요.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ade77e-27b2-4032-86f8-d9a395d47db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'부영그룹은 출산한 직원의 자녀에 1억원씩 지원하고 총 70억원을 지원한다. 이 정책은 부영그룹이 세째까지 아이를 낳는 경우 국민주택을 제공할 것을 언급했다.  부영그룹이 내놓은 이 행사는 사회적 분위기를 바꿀 것으로 기대받고 있다. \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\n",
    "    \"부영그룹의 임직원 숫자는 몇명인가요?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12a0f49-6153-466a-9c5a-85a3f9b3f74b",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf0ec87-a0c6-45b2-b00c-a3cc95758a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87515ce7-6b85-49e9-b07c-63d5d3a36cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 23\n",
      "\n",
      "[페이지내용]\n",
      "SPRi AI Brief |  \n",
      "2023-12 월호\n",
      "8코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기 ’ 플랫폼을 출시\n",
      "n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능KEY Contents\n",
      "£데이터 출처 탐색기 , 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "nAI 기업 코히어 (Cohere) 가 매사추세츠 공과⼤(MIT), 하버드 ⼤ 로스쿨 , 카네기멜론 ⼤ 등 12개 기관과  \n",
      "함께 2023 년 10월 25일 ‘데이터 출처 탐색기 (Data Provenance Explorer)’ 플랫폼을 공개\n",
      "∙AI 모델 훈련에 사용되는 데이터셋의 불분명한 출처로 인해 데이터 투명성이 확보되지 않아 다양한 \n",
      "법적·윤리적 문제가 발생\n",
      "∙이에 연구\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5918460-2e4e-448b-8f74-9235f421c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a546c385-68d8-4641-a432-86baa7950a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OllamaEmbeddings(model=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779c2887-fb2c-419a-80be-5a3fc8cd2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(f\"data/faiss_spri_{model_name.replace(':','-')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b7d2e47-9b9d-4b98-bd3b-e42bb3196667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bdeb1d6-b405-43de-b176-c8313c45fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"중국의 알리바바 클라우드가 무엇을 공개했나요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc25236-3f9a-4f68-8b0b-44eda3a95576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\rag-f3KTP8yE-py3.12\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 22}, page_content='홈페이지 : https://spri.kr/\\n보고서와 관련된 문의는 AI정책연구실 (jayoo@spri.kr, 031-739-7352) 으로 연락주시기 바랍니다 .'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\\nn삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스 ’를 공개\\nn삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\\nn삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스 ’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 , \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며 , 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는  \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며 , 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이 (code.i)’ 는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nnIT 전문지 테크리퍼블릭 (TechRepublic) 은 온디바이스 AI가 주요 기술 트렌드로 부상했다며 ,'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 2}, page_content='Ⅰ. 인공지능 산업 동향 브리프'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21}, page_content='행사명 행사 주요 개요\\nCES 2024\\n-미국 소비자기술 협회(CTA) 가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스 , 교통·모빌리티 등 \\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n-CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며 , \\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한 \\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\nAIMLA 2024\\n-머신러닝 및 응용에 관한 국제 컨퍼런스 (AIMLA 2024) 는 \\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 \\n지식과  최신 연구 결과 공유\\n-이론 및 실무 측면에서 인공지능 , 기계학습의 주요 분야를 \\n논의하고 , 학계, 산업계의 연구자와 실무자들에게 해당 분\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\n2024.1.27~28 덴마크 , 코펜하겐https://ccnet2024.org/aimla\\n/index\\nAAAI Conference \\non Artificial \\nIntelligence\\n-AI 발전 협회 컨퍼런스 (AAAI) 는 AI 연구를 촉진하고 , AI 분야 \\n연구원 , 실무자 , 과학자 , 학생 및 공학자 간 교류의 기회 제공\\n-컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, \\n워크숍 , 튜토리얼 , 포스터 세션, 주제 발표, 대회, 전시 프\\n로그램 등 진행   \\n기간 장소 홈페이지\\n2024.2.20~27 캐나다 , 밴쿠버https://aaai.org/aaai-confere\\nnce/\\nⅡ. 주요 행사 일정')]\n"
     ]
    }
   ],
   "source": [
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e25c7c08-3006-434f-b02e-6293f0e0171e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 22}, page_content='홈페이지 : https://spri.kr/\\n보고서와 관련된 문의는 AI정책연구실 (jayoo@spri.kr, 031-739-7352) 으로 연락주시기 바랍니다 .'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\\nn삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스 ’를 공개\\nn삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\\nn삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스 ’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 , \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며 , 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는  \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며 , 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이 (code.i)’ 는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nnIT 전문지 테크리퍼블릭 (TechRepublic) 은 온디바이스 AI가 주요 기술 트렌드로 부상했다며 ,'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 2}, page_content='Ⅰ. 인공지능 산업 동향 브리프'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21}, page_content='행사명 행사 주요 개요\\nCES 2024\\n-미국 소비자기술 협회(CTA) 가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스 , 교통·모빌리티 등 \\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n-CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며 , \\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한 \\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\nAIMLA 2024\\n-머신러닝 및 응용에 관한 국제 컨퍼런스 (AIMLA 2024) 는 \\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 \\n지식과  최신 연구 결과 공유\\n-이론 및 실무 측면에서 인공지능 , 기계학습의 주요 분야를 \\n논의하고 , 학계, 산업계의 연구자와 실무자들에게 해당 분\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\n2024.1.27~28 덴마크 , 코펜하겐https://ccnet2024.org/aimla\\n/index\\nAAAI Conference \\non Artificial \\nIntelligence\\n-AI 발전 협회 컨퍼런스 (AAAI) 는 AI 연구를 촉진하고 , AI 분야 \\n연구원 , 실무자 , 과학자 , 학생 및 공학자 간 교류의 기회 제공\\n-컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, \\n워크숍 , 튜토리얼 , 포스터 세션, 주제 발표, 대회, 전시 프\\n로그램 등 진행   \\n기간 장소 홈페이지\\n2024.2.20~27 캐나다 , 밴쿠버https://aaai.org/aaai-confere\\nnce/\\nⅡ. 주요 행사 일정')]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")\n",
    "\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6e03873-6756-406c-8941-1cbb0063993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 22}, page_content='홈페이지 : https://spri.kr/\\n보고서와 관련된 문의는 AI정책연구실 (jayoo@spri.kr, 031-739-7352) 으로 연락주시기 바랍니다 .'), Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\\nn영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 \\n위한 협력 방안을 담은 블레츨리 선언을 발표\\nn첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며 , \\n영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정 KEY Contents\\n£AI 안전성 정상회의 참가국들 , 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\\nn2023 년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의 (AI Safety Summit) 에 \\n참가한 28개국 대표들이  AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 \\n∙선언은 AI 안전 보장을 위해 국가, 국제기구 , 기업, 시민사회 , 학계를 포함한 모든 이해관계자의 협력이 \\n중요하다고 강조했으며 , 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여 \\nAI 시스템의 안전을 보장할 책임이 있다고 지적\\n∙각국은 AI 안전 보장을 위해 첨단 AI 개발기업의 투명성 향상, 적절한 평가지표와 안전 테스트 도구 \\n개발, 공공부문 역량 구축과 과학 연구개발 등의 분야에서 협력하기로 합의\\n£영국 총리, 정부 주도의 첨단 AI 시스템 안전 테스트 계획 발표\\nn리시 수낙 영국 총리는 AI 안전성 정상회의를 마무리하며 첨단 AI 모델에 대한 안전성 시험 계획 \\n수립과  테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표\\n∙첨단 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한 \\n시험을 포함하며 , 참석자들은 정부 주도의 외부 안전 테스트에 합의\\n∙각국 정부는 테스트와 기타 안전 연구를 위한 공공부문 역량에 투자하고 , 테스트 결과가 다른 국가와')]\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "search_result = retriever.get_relevant_documents(query)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7224561f-051f-4d65-a854-3c60dd9c8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4fb08e-0262-4f6e-ba24-9e1080e0be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8a96d60-48a9-47f0-8f11-fc2b35548456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa0c3c41-260f-4f94-bd00-fbb500c0aa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['Here are three alternative versions of the original question, each aiming to improve relevance for a vector database search:', '1. **\"What public services/products related to Alibaba Cloud\\'s cloud platform in China have been announced?\"** (Focuses on specific service offerings)', '2. **\"Which Chinese companies or organizations used Alibaba Cloud\\'s cloud services and launched their own products/platforms in the past year?\"** (Targets real-world examples of application)', '3. **\"What are the key features and capabilities of Alibaba Cloud\\'s public offerings for businesses in China?\"**  (Emphasizes product-level details, potentially with more specific keywords) ', 'These alternatives use different strategies to address the limitations of distance-based similarity search:', '* **Specific Queries:** The first version focuses on specific types of services/products. This narrows the scope and could yield more precise results for a vector database.', '* **Contextual Information:** The second version incorporates real-world scenarios, helping capture user intent and possibly identify relevant documents based on similar situations. ', '* **Detailed Features:**  The third version highlights desired product attributes.  This may lead to matching documents even if the exact terms are not precisely matched in the database.', \"Ultimately, the best alternative depends on the specific use case of the user's search.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=query)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43333e-40b7-4781-9b68-b48a4829791e",
   "metadata": {},
   "source": [
    "## BM25 / Ensemble Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1017ab00-5022-4396-b724-cbc91381f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a9928-d15e-485c-94fb-a2fa371cc5ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 배"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfaeba93-e986-4581-9cd6-d4bc286e3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    \"난 오늘 많이 먹어서 배가 정말 부르다\",\n",
    "    \"떠나는 저 배가 오늘 마지막 배인가요?\",\n",
    "    \"내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\",\n",
    "]\n",
    "\n",
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de7cfa77-eb18-4d02-90a3-38499ffbb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore = FAISS.from_texts(doc_list, OllamaEmbeddings(model=model_name))\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "faa41cdf-e26e-4b7d-aadd-c5d8b552e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"[{i+1}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9112822a-4f0d-4601-ab57-ef365b8eea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query]\n",
      "나 요즘 배에 정말 살이 많이 쪘어...\n",
      "\n",
      "[BM25 Retriever]\n",
      "[1] 난 오늘 많이 먹어서 배가 정말 부르다\n",
      "[2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
      "============================================================\n",
      "[FAISS Retriever]\n",
      "[1] 떠나는 저 배가 오늘 마지막 배인가요?\n",
      "[2] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
      "============================================================\n",
      "[Ensemble Retriever]\n",
      "[1] 내가 제일 좋아하는 과일들은 배, 사과, 키워, 수박 입니다.\n",
      "[2] 난 오늘 많이 먹어서 배가 정말 부르다\n",
      "[3] 떠나는 저 배가 오늘 마지막 배인가요?\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"나 요즘 배에 정말 살이 많이 쪘어...\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.get_relevant_documents(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "760dd145-5cd3-45f5-a751-9dd69dc29d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf70878-78bd-4d9d-a414-e5998373cabe",
   "metadata": {},
   "source": [
    "### PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d87247-3496-4e4b-b29a-1aea7f5894b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 문서를 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "file_path = \"data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 단계 3, 4: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e9c1eb8-51d5-4be8-9ccf-8cbbfc0f0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 5: 리트리버 생성(Create Retriever)\n",
    "# 사용자의 질문(query) 에 부합하는 문서를 검색합니다.\n",
    "\n",
    "# 유사도 높은 K 개의 문서를 검색합니다.\n",
    "k = 3\n",
    "\n",
    "# (Sparse) bm25 retriever and (Dense) faiss retriever 를 초기화 합니다.\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29377277-c285-4e44-801a-0ad7206a39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore = FAISS.from_documents(split_docs, OllamaEmbeddings(model=model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1dff120-f770-44f1-8549-93ac8fbec889",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98ded7e-9f72-416d-99cc-a62263fb4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4defb505-c924-44cc-bac5-957cf746072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 단계 7: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOllama(\n",
    "    model=model_name,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d74bccd-adee-4334-8940-71f46a17c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# 단계 8: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2633a30d-1bb3-48aa-8fc7-77c37746bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Gauss is a generative AI model developed by Samsung that operates on an on-device basis.  It uses language, code, and image models to create text, code, and images.  The model aims for safety and functionality by training on secure data. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"삼성 가우스에 대해 설명해주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa672d4f-af6d-4c30-9cc4-dcef449dd341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 23\n",
      "============================================================\n",
      "[HUMAN]\n",
      "삼성 가우스에 대해 설명해주세요\n",
      "\n",
      "[AI]\n",
      "Samsung Gauss is a generative AI model developed by Samsung that operates on an on-device basis.  It uses language, code, and image models to create text, code, and images.  The model aims for safety and functionality by training on secure data. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "# print(f\"PDF Path: {file_path}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05db655a-1441-408b-a3c4-2eb5f1f54fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 삼성 기술, AI 모델 선택 및 전망 분석\n",
      "\n",
      "본문에서 설명된 주요 내용들을 요약하고 각각의 의사 결정을 위한 조언을 제시합니다.\n",
      "\n",
      "**1. 삼성 가우스와 온디바이스 AI 기술:**\n",
      "\n",
      "* **안전성**: 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터로 학습되었으며, 외부 유출 가능성이 매우 적음.  \n",
      "* **장점**: 온디바이스 AI 기술을 활용할 수 있고 다양한 제품에 단계적으로 탑재될 예정.\n",
      "\n",
      "**2. 삼성 전자의 AI 모델과 전망:**\n",
      "\n",
      "* **삼성 가우스**는 언어, 코드, 이미지 세 가지 모델로 구성되어 있으며 각각은:\n",
      "    * **언어 모델**: 메일 작성, 문서 요약, 번역 등 다양한 업무 지원. \n",
      "    * **코드 모델 (code.i)** : 대화형 인터페이스를 통해 소프트웨어 개발 도움.\n",
      "    * **이미지 모델**: 창의적 이미지 생성 및 기존 이미지 변환 기능 제공.  \n",
      "\n",
      "* **전망:** 삼성 전자는 단계적으로 온디바이스 AI 기술을 적용하여 다양한 제품에 활용하고, 더욱 발전된 모델들을 개발할 예정.\n",
      "\n",
      "**3. 딥마인드의 AGI 프레임워크:**\n",
      "\n",
      "* **6단계 구분**:  구글 딥마인드는 범용 AI (AGI) 의 수준을 0~5단계로 분류하여 연구하고 있습니다. \n",
      "    * 현재 챗봇과 같은 AI 솔루션은 AGI 1단계 수준\n",
      "    * 실제 AGI 개발에 있어서는 아직 많은 과정이 필요합니다.\n",
      "\n",
      "**4.  AI 혁신의 미래:**\n",
      "\n",
      "* **반복적인 작업**: AI가 반복적 작업을 자동화하는 데 집중해야 합니다. \n",
      "* **인지력 향상**: 인간과 같은 인지 기능을 통해 더욱 풍부한 결과를 얻고 더 나은 의사 결정을 할 수 있어야 합니다. \n",
      "\n",
      "**5.  결론:** 삼성은 AI 기술의 진보 속에서 안전하고 경쟁력 있는 제품을 개발하기 위한 노력을 계속합니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"미래의 AI 소프트웨어 매출 전망은 어떻게 되나요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23e29002-63bb-4066-9776-a3a4b14391e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##  AI & Machine Learning Conference Information\n",
      "\n",
      "This document provides information about upcoming AI and machine learning conferences with details on their location, schedule, key highlights, and resources.\n",
      "\n",
      "**1. AAAI Conference:**\n",
      "* **Date:** 2024.1.27~28 (Copenhagen, Denmark) \n",
      "* **Website:** https://ccnet2024.org/aimla/index \n",
      "* **Description:**  This is the annual Association for the Advancement of Artificial Intelligence (AAAI) conference. It aims to advance AI research and provide a platform for communication between researchers, industry professionals, students, and engineers.  \n",
      "    * **Events:** The conference features technical presentations, special tracks, invited speakers, workshops, tutorials, poster sessions, keynote talks, competitions, and an exhibition program. \n",
      "\n",
      "\n",
      "**2. SPRi AI Brief:**\n",
      "* **Date:** December 2023 (issue)\n",
      "* **Source:** IDC - International Data Corporation\n",
      "* **Main points:**\n",
      "    *  IDC predicts the global AI software market will reach $2.5 billion by 2027, with an expected increase of 31.4% year-on-year growth. \n",
      "    *  **Key areas driving this growth**:\n",
      "        *  **AI Software Market Size:** The global AI software market is expanding rapidly and includes:\n",
      "            * **AI Platforms:** the backbone for developing advanced applications. \n",
      "            * **AI Applications:** the direct tools that help businesses with various tasks, such as customer relationship management (CRM), supply chain management, and more. \n",
      "            *  **Software Development Tools:** AI-powered tools to develop, deploy and manage AI applications are becoming crucial. \n",
      "        *   AI Platforms: a key driver of growth in the market\n",
      "    * **2027 Market Forecast**: The global market for AI software is expected to reach $5 billion by 2027, with an estimated 21.1% annual growth rate.  \n",
      "    * **Software Application Development and Management:** This section focuses on the role of development tools, quality management, and lifespan extension in achieving successful AI application deployment.\n",
      "\n",
      "**3. Conference Locations & Dates:**\n",
      " * **Conference 1:** AAAI Conference (2024.1.27~28) - Copenhagen, Denmark \n",
      " *  **Conference 2:** SPRi AI Brief (December 2023) - Available online\n",
      "\n",
      "\n",
      "This information provides a starting point for those interested in the world of Artificial Intelligence and Machine Learning research and development.  \n",
      "\n",
      "Let me know if you need further details on specific topics or would like more information about these conferences! \n"
     ]
    }
   ],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"YouTube 가 2024년에 의무화 한 것은 무엇인가요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef33a5-0083-44de-9433-33a2aed3c407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3dbee-13d6-4ac0-a0a7-98bef2b926e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2539a-fb31-4c10-9085-a8b7e5361b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d52f75-473a-4cb9-8ba3-b46e1e8e3aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
